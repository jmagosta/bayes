{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Single Decisions\n",
    "\n",
    "## The \"Party Problem\" example\n",
    "\n",
    "JMA 11 Jan 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from the python standard library\n",
    "import math, re, os, sys\n",
    "from pathlib import Path\n",
    "import itertools            # to flatten lists\n",
    "\n",
    "# Import array and dataframe packages\n",
    "import numpy as np\n",
    "# import numpy.linalg as la\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "# for extract_net\n",
    "# from ID_operations import * \n",
    "from potential_operations import *\n",
    "import BN\n",
    "\n",
    "# Import the bokeh python wrappers for javascript plots\n",
    "#  - a preferred visualization tool\n",
    "# from bokeh.plotting import figure, show\n",
    "# from bokeh.models import ColumnDataSource, VBar, Span\n",
    "# from bokeh.io import output_notebook\n",
    "# output_notebook()\n",
    "\n",
    "NETWORK_FILE = 'PartyProblem_asym.xdsl' # 'PartyProblem_asym.xdsl'  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BN structure is contained under the node branch\n",
    "parsed = BN.extract_net(NETWORK_FILE)\n",
    "nodes, extensions = parsed\n",
    "# tags tell the node type. \n",
    "[( k.get('id'), k.tag) for k in nodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes networks object\n",
    "\n",
    "### Include state and variable names to tensor dimensions\n",
    "\n",
    "### Add graph structure\n",
    "\n",
    "It contains \n",
    "\n",
    "- the parse of the network as a dictionary with node names as keys\n",
    "- The graph object showing network structure\n",
    "- Node Potential objects for computation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPT contents are stored in row major order (first row, second row, ...)\n",
    "# Parents are the first matrix dimension -- matrix is Row Markov\n",
    "pp_net = BN.reap(parsed)\n",
    "pp_net.pr_nodes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_net.pr_influences()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract matrices as tensors.  _List all tensors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_net.pr_named_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move to BN class\n",
    "\n",
    "pp_net.pr_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pretty print one of the variables\n",
    "pp_net.pr_one_dim_table( 'Weather', tablefmt= '.4f', headers= ['State', 'Value'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility matrix, as a Potential\n",
    "outcome_potential = pp_net.get_potential('Preferences')\n",
    "outcome_potential.pr_potential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_p = named_tensor_apply(outcome_potential, delta_utility, exponand = 0.5, normalize = 50)\n",
    "utility_p.pr_potential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_tensor_apply(utility_p, delta_inverse_utility, exponand = 0.5, normalize = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the party problem\n",
    "\n",
    "_Using just potential operations (not Node removal)\n",
    "\n",
    "To determine the optimal policy --\n",
    "\n",
    "* join Adjustor and Detector CPTs, marginalize out Adjustor\n",
    "* join Detector and Weather CPTs, marginalize out Detector \n",
    "* join Weather with Utility (Decision has unit values for all options)\n",
    "* marginalize out unobserved Weather \n",
    "* Maximize over options\n",
    "* (marginalize out Utility to get decision lottery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First solution - only prior, no observation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Adjustor\n",
    "detector_p = pp_net.get_potential('Detector')\n",
    "adjustor_p = pp_net.get_potential('Adjustor')\n",
    "detector_marginal = absorb_parent(adjustor_p, detector_p)\n",
    "detector_marginal.pr_potential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Detector\n",
    "# Note this just returns the Weather prior, as it should. \n",
    "weather_p = pp_net.get_potential('Weather')\n",
    "wd_joint = join(weather_p, detector_marginal)  #TODO wrap these in a reverse arc & remove function\n",
    "weather_marginal = marginalize(wd_joint, 'Detector')\n",
    "weather_marginal.pr_potential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must we drop the singleton dim first from the utility?\n",
    "utility_p.pr_potential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility expected value over decision alternatives\n",
    "# TODO wrap this in a high level function\n",
    "squeezed_utility = drop_singleton_dimension(utility_p)\n",
    "joined_utility = join(weather_marginal, squeezed_utility)\n",
    "expected_utility = marginalize(joined_utility, 'Weather')\n",
    "print('Alternatives:',pp_net.get_node('Party_location').get_states())\n",
    "expected_utility.pr_potential()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Party problem 2; when Weather is observed\n",
    "\n",
    "To solve this --\n",
    "\n",
    "* Add an informational \"cause\" to the decision node by\n",
    "* Using the Weather marginal as a conditioning for Party location\n",
    "\n",
    "_alternately add the conditioning arc in the xdsl file instead of programmatically modifying it._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P( Weather | Detector) - column markov\n",
    "# See p 270 Figure 13.6\n",
    "# Modify the decision node, and add the weather dimension to its Potential. \n",
    "decn_node = pp_net.get_node('Party_location')\n",
    "decn_p = decn_node.get_potential()\n",
    "decn_dims = decn_p.get_named_dims()\n",
    "# Prefix the weather 'm' dim OrderedDict has a function for this\n",
    "decn_dims['Weather'] = 'm'\n",
    "decn_dims.move_to_end('Weather', last=False)\n",
    "# Prefix a dimension to the decision cpt table\n",
    "# Use the global weather potential\n",
    "conditioning_size = weather_p.get_dim_sizes()[-1]    # Marginal dim is last\n",
    "extended_shape = list(decn_p.get_dim_sizes())\n",
    "extended_shape.insert(0, conditioning_size)\n",
    "cpt = torch.ones(extended_shape)\n",
    "extended_decn_p = Potential(cpt, decn_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: Create the modified net and draw its graph_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  weather and utility\n",
    "# join utility and extended decn? / maximize decn, join & marginalize weather? \n",
    "squeezed_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One approach is to add a unsqueeze dim to match Detector at the end of preference transpose\n",
    "# BINGO\n",
    "extended_preference = preference_transpose.p.unsqueeze(-1).unsqueeze(-1)\n",
    "print(extended_preference.shape)\n",
    "# Sum out the weather dimension\n",
    "policy_values = (extended_preference * posterior.p).sum(2)\n",
    "print('E[ V | Party_location, Detector] = ')\n",
    "policy_values\n",
    "# Next we need to weight the optimal in each column by the pre-posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_preference * posterior.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Need to format list entries before passing to tabulate. \n",
    "# TODO looks like the State labels are flipped. \n",
    "detector_states= pp_net.n_dict['Detector']['states'].copy()\n",
    "detector_states.insert(0, 'State')\n",
    "pr_one_dim_table(policy_values.squeeze(0), \n",
    "    'Party_location',\n",
    "    pp_net.n_dict, \n",
    "    floatfmt= \".3f\", \n",
    "    headers= detector_states)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_values.squeeze(0).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO what is the last dim?  Need to remove it. \n",
    "fig, ax = plt.subplots(1,2, figsize = (6, 2.6))\n",
    "policy_values_2d_a = pd.DataFrame(policy_values.squeeze(0)[:,:,1], columns = pp_net.n_dict['Detector']['states'], \n",
    "                                index = pp_net.n_dict['Party_location']['states'])\n",
    "sn.heatmap(policy_values_2d_a, annot=True, xticklabels=True, yticklabels=True, ax=ax[0])\n",
    "policy_values_2d_b = pd.DataFrame(policy_values.squeeze(0)[:,:,0], columns = pp_net.n_dict['Detector']['states'], \n",
    "                                index = pp_net.n_dict['Party_location']['states'])\n",
    "sn.heatmap(policy_values_2d_b, annot=True, xticklabels=True, yticklabels=True, ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the max value in each column. \n",
    "decn = policy_values.max(1)\n",
    "decn.values, decn.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value with information. \n",
    "# However utility should be applied after computing expected values to get certain equivalents\n",
    "# sigh\n",
    "# 0.7782 * 0.44 + 0.6557 * 0.56\n",
    "decn.values @ get_potential('Weather', pp_net.n_dict).p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
